{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d762d280",
   "metadata": {},
   "source": [
    "# HNLQ: Part-01\n",
    "\n",
    "In this series of notebooks, we will demonstrate **hierarchical nested lattice quantization** using the D4 lattice, showing how multi-level quantization can improve rate-distortion performance.\n",
    "\n",
    "In Part-01, we primarily check the API for creating the quantizer object, and see it side-by-side by with NLQ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ece85f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from gemvq.quantizers.hnlq import HNLQ as Quantizer\n",
    "from gemvq.quantizers.hnlq import HNLQConfig as QuantizerConfig\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c45f7b",
   "metadata": {},
   "source": [
    "## Object Instantiation\n",
    "\n",
    "An important observation. In terms API and implementation HNLQ and NLQ are very similar. In fact, NLQ is special case of HNLQ with M=1.  Therefore, whatever we observed for NLQ, we should observe for NLQ with M=1.\n",
    "\n",
    "The NLQ API is a strict subset of HNLQ API. That is what we will see below, as sanity check."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f2d86f",
   "metadata": {},
   "source": [
    "### via Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ada5a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vector: [ 0.80024382 -0.57503248  0.43420994 -0.66393914]\n",
      "Lattice type: D4\n",
      "Input: [ 0.80024382 -0.57503248  0.43420994 -0.66393914]\n",
      "Encoded: (array([0, 1, 0, 1]),)\n",
      "Scaling iterations: 0\n",
      "Reconstructed: [ 1. -1.  1. -1.]\n",
      "Error: 0.163389\n"
     ]
    }
   ],
   "source": [
    "# create a quantizer for D4 lattice using QuantizerConfig object\n",
    "\n",
    "# Method 1: Using QuantizerConfig object (most explicit)\n",
    "config = QuantizerConfig(\n",
    "    lattice_type='D4',      # Automatically loads D4 lattice components\n",
    "    q=2,                    # Quantization parameter (alphabet size)\n",
    "    beta=1.0,              # Scaling parameter for quantization\n",
    "    alpha=0.5,             # Scaling parameter for overload handling\n",
    "    eps=1e-8,              # Small perturbation parameter\n",
    "    overload=True,          # Handle overload by scaling\n",
    "    max_scaling_iterations=10,\n",
    "    with_tie_dither=True,   # Add dither for tie breaking\n",
    "    with_dither=False,       # No randomized dither    ,\n",
    "    M =1,\n",
    "    decoding='full'\n",
    ")\n",
    "\n",
    "quantizer = Quantizer(config)\n",
    "\n",
    "def print_quantizer_summary(quantizer):\n",
    "    d = len(quantizer.G)\n",
    "    x = np.random.randn(d)\n",
    "    x = x/np.sqrt(np.linalg.norm(x))\n",
    "    print(\"Original vector:\", x)\n",
    "\n",
    "\n",
    "    x_hat = quantizer.quantize(x)\n",
    "    \n",
    "\n",
    "    enc, T = quantizer.encode(x)\n",
    "    x_dq = quantizer.decode(enc, T)\n",
    "\n",
    "    \n",
    "    print(f\"Lattice type: {quantizer.lattice_type}\")\n",
    "    print(f\"Input: {x}\")\n",
    "    print(f\"Encoded: {enc}\")\n",
    "    print(f\"Scaling iterations: {T}\")\n",
    "    print(f\"Reconstructed: {x_hat}\")\n",
    "    print(f\"Error: {np.mean((x - x_hat)**2):.6f}\")\n",
    "\n",
    "\n",
    "print_quantizer_summary(quantizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4241ea",
   "metadata": {},
   "source": [
    "###  via Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d4c9d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vector: [-0.49306207  0.0034824   1.55767593  0.46000833]\n",
      "Lattice type: D4\n",
      "Input: [-0.49306207  0.0034824   1.55767593  0.46000833]\n",
      "Encoded: (array([2, 2, 1, 0]), array([0, 0, 0, 0]), array([0, 0, 0, 0]))\n",
      "Scaling iterations: 0\n",
      "Reconstructed: [0. 0. 2. 0.]\n",
      "Error: 0.162595\n"
     ]
    }
   ],
   "source": [
    "# Create configuration as dictionary\n",
    "config_dict = {\n",
    "    'lattice_type': 'D4',\n",
    "    'q': 3,\n",
    "    'beta': 1.0,\n",
    "    'alpha': 1.0,\n",
    "    'eps': 1e-8,\n",
    "    'M': 3,\n",
    "    'overload': True,\n",
    "    'decoding': 'coarse_to_fine',\n",
    "    'max_scaling_iterations': 10,\n",
    "    'with_tie_dither': True,\n",
    "    'with_dither': False\n",
    "}\n",
    "\n",
    "# Create HNLQ with configuration dictionary\n",
    "quantizer = Quantizer(config_dict)\n",
    "print_quantizer_summary(quantizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1089cf52",
   "metadata": {},
   "source": [
    "### via specialized constructors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45aaa2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vector: [ 0.97886112 -1.40825796]\n",
      "Lattice type: Z2\n",
      "Input: [ 0.97886112 -1.40825796]\n",
      "Encoded: (array([1, 2]), array([0, 0]), array([0, 0]))\n",
      "Scaling iterations: 0\n",
      "Reconstructed: [ 1. -1.]\n",
      "Error: 0.083561\n"
     ]
    }
   ],
   "source": [
    "# Create ZÂ² hierarchical quantizer\n",
    "quantizer = Quantizer.create_z2_quantizer(\n",
    "    q=3,\n",
    "    M=3,\n",
    "    beta=1.0,\n",
    "    alpha=1.0,\n",
    "    eps=1e-8,\n",
    "    overload=True,\n",
    "    decoding='full',\n",
    "    with_tie_dither=True,\n",
    "    with_dither=False\n",
    ")\n",
    "print_quantizer_summary(quantizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4127bd53",
   "metadata": {},
   "source": [
    "### via Custom Lattice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41cca248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vector: [-1.29384757 -0.49603486]\n",
      "Lattice type: Z2\n",
      "Input: [-1.29384757 -0.49603486]\n",
      "Encoded: (array([2, 0]), array([0, 0]))\n",
      "Scaling iterations: 0\n",
      "Reconstructed: [-1.  0.]\n",
      "Error: 0.166198\n"
     ]
    }
   ],
   "source": [
    "# Define custom generator matrix and closest point function\n",
    "G_custom = np.array([[1, 0], [0, 1]])  # 2x2 identity matrix\n",
    "def custom_closest_point(x):\n",
    "    return np.floor(x + 0.5)\n",
    "\n",
    "# Create configuration\n",
    "config = QuantizerConfig(\n",
    "    lattice_type='Z2',  # Can be any supported type\n",
    "    q=3,\n",
    "    M=2,\n",
    "    beta=1.0,\n",
    "    alpha=1.0,\n",
    "    eps=1e-8\n",
    ")\n",
    "\n",
    "# Create HNLQ with custom components\n",
    "quantizer = Quantizer(config, G=G_custom, Q_nn=custom_closest_point)\n",
    "print_quantizer_summary(quantizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3554294",
   "metadata": {},
   "source": [
    "### with Minimal Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c95fc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vector: [ 0.09370087 -0.51599423 -0.04602902  0.9699695 ]\n",
      "Lattice type: D4\n",
      "Input: [ 0.09370087 -0.51599423 -0.04602902  0.9699695 ]\n",
      "Encoded: (array([0, 0, 2, 2]), array([0, 0, 0, 0]), array([0, 0, 0, 0]))\n",
      "Scaling iterations: 0\n",
      "Reconstructed: [ 0. -1.  0.  1.]\n",
      "Error: 0.061515\n"
     ]
    }
   ],
   "source": [
    "# Minimal configuration with defaults\n",
    "config_minimal = QuantizerConfig(\n",
    "    lattice_type='D4',\n",
    "    q=3,\n",
    "    M=3\n",
    "    # All other parameters use defaults\n",
    ")\n",
    "quantizer = Quantizer(config_minimal)\n",
    "print_quantizer_summary(quantizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054c0928",
   "metadata": {},
   "source": [
    "### Different decoding strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "607b30fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full decoding (default)\n",
    "hnlq_full = Quantizer.create_d4_quantizer(q=3, M=3, decoding='full')\n",
    "\n",
    "# Coarse-to-fine decoding\n",
    "hnlq_coarse = Quantizer.create_d4_quantizer(q=3, M=3, decoding='coarse_to_fine')\n",
    "\n",
    "# Progressive decoding\n",
    "hnlq_progressive = Quantizer.create_d4_quantizer(q=3, M=3, decoding='progressive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bd34be",
   "metadata": {},
   "source": [
    "### Advanced configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84c30561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced configuration with all parameters specified\n",
    "config_advanced = QuantizerConfig(\n",
    "    lattice_type='E8',\n",
    "    q=4,\n",
    "    beta=0.5,\n",
    "    alpha=1.5,\n",
    "    eps=1e-10,\n",
    "    M=4,\n",
    "    overload=False,\n",
    "    decoding='progressive',\n",
    "    max_scaling_iterations=20,\n",
    "    with_tie_dither=False,\n",
    "    with_dither=True\n",
    ")\n",
    "\n",
    "hnlq_advanced = Quantizer(config_advanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9801e800",
   "metadata": {},
   "source": [
    "## A simple example\n",
    "of using hierarchical lattice quantization to quantize a 4D vector.\n",
    "\n",
    "We will take $x=(1.2,-0.7,2.4,0.3)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "757310ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vector: [ 0.43022084 -0.25096216  0.86044169  0.10755521]\n",
      "Quantized vector: [1. 0. 1. 0.]\n",
      "encoded: (array([1, 0, 1, 0]),)\n",
      "overloading factor: 0\n",
      "Decoded vector: [1. 0. 1. 0.]\n",
      "Reconstruction Error (L2 norm): 0.647051\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(31)\n",
    "\n",
    "q = 2\n",
    "beta = 1\n",
    "alpha = 1\n",
    "eps = 1e-8\n",
    "M = 1\n",
    "lattice_type = 'D4'\n",
    "config = QuantizerConfig(lattice_type=lattice_type, q=q, beta=beta, alpha=alpha, eps=eps, M=M)\n",
    "quantizer = Quantizer(config)\n",
    "    \n",
    "    \n",
    "\n",
    "# Create test sample and normalize it\n",
    "test_sample = np.array([1.2, -0.7, 2.4, 0.3])\n",
    "test_sample = test_sample/np.linalg.norm(test_sample)  # normalize to unit vector\n",
    "print(\"Original vector:\", test_sample)\n",
    "\n",
    "# Test quantization\n",
    "x_q = quantizer.quantize(test_sample, with_dither=False)\n",
    "print(\"Quantized vector:\", x_q)\n",
    "\n",
    "# Test encode/decode separately\n",
    "enc, T = quantizer.encode(test_sample, with_dither=False)\n",
    "x_dq = quantizer.decode(enc, T, with_dither=False)\n",
    "print(\"encoded:\", enc)\n",
    "print(\"overloading factor:\", T)\n",
    "print(\"Decoded vector:\", x_dq)\n",
    "\n",
    "# Print error\n",
    "error = np.linalg.norm(test_sample - x_dq)\n",
    "print(f\"Reconstruction Error (L2 norm): {error:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
